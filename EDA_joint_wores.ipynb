{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices - Regression Predictions YData 2024    \n",
    "\n",
    "**Team: Random Forest Rangers** ([Dmitry Gufranov](https://www.linkedin.com/in/gufranov/), [Evgenia Amineva](https://www.linkedin.com/in/janeami/), [Valeriya Vazhnova](https://www.linkedin.com/in/gufranov/))\n",
    "\n",
    "## Part 1. EDA\n",
    "\n",
    "The EDA below answers the following questions:\n",
    "\n",
    "* [Which 3 features have the highest number of missing values](#first_q)\n",
    "* [How the price behave over the years?](#second_q)\n",
    "* [Plot the the feature distribution using histograms](#third_q)\n",
    "* [Compute and order the features by their correlation with label](#fourth_q)\n",
    "* [Add more EDA that will help you understand the data and support your modeling decisions](#fifth_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import datetime\n",
    "\n",
    "# vizualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "\n",
    "# ml\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train data\n",
    "df = pd.read_csv('train.csv')\n",
    "display(df.head())\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info about the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check empty columns\n",
    "print(\"Number of empty columns:\", df.isnull().all().sum(), \"\\n\")\n",
    "\n",
    "# check duplicates\n",
    "print(\"Number of duplicates (Id column is disregarded):\", df.drop(columns=['Id']).duplicated().sum(), \"\\n\")\n",
    "\n",
    "# check uniqueness of Id\n",
    "print(\"All Ids are unique:\", df['Id'].is_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 3 features with the highest number of missing values <a class=\"anchor\" id=\"first_q\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of missing values\n",
    "missing_val = df.isnull().sum()\n",
    "missing_val = missing_val[missing_val > 0] / df.shape[0] *100\n",
    "missing_val.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "print(\"Percantage of missing values by columns: \\n\\n\",missing_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of missing values among the 3 features with the most missing values\n",
    "df.isnull().sum().sort_values(ascending=False)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the information about the features with the highest number of missing values in the data description file\n",
    "\n",
    "<b>PoolQC</b>: Pool quality\n",
    "\t\t\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tAverage/Typical\n",
    "       Fa\tFair\n",
    "       NA\tNo Pool\n",
    "\n",
    "<b>MiscFeature</b>: Miscellaneous feature not covered in other categories\n",
    "\t\t\n",
    "       Elev\tElevator\n",
    "       Gar2\t2nd Garage (if not described in garage section)\n",
    "       Othr\tOther\n",
    "       Shed\tShed (over 100 SF)\n",
    "       TenC\tTennis Court\n",
    "       NA\tNone\n",
    "\n",
    "<b>Alley</b>: Type of alley access to property\n",
    "\n",
    "       Grvl\tGravel\n",
    "       Pave\tPaved\n",
    "       NA \tNo alley access\n",
    "\n",
    "It appears that NA value has a meaning according to the data description file. Let's take a closer look at the values in these columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['PoolQC', 'MiscFeature', 'Alley']:\n",
    "    print(df[c].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 'NA' doesn't appear as a separate value in the columns above, for the columns 'PoolQC' and 'Alley' we can consider it as significant information meaning 'No Pool' and 'No alley access' respectfully. It may be useful for our main goal and later we will need to fill them with 'NA' label.\n",
    "\n",
    "Also, information about the Pool should match between the columns 'PoolQC' and 'PoolArea', let's check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['PoolArea']!=0]['PoolArea'].count() == df[~df['PoolQC'].isna()]['PoolQC'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Price behavior over the years <a class=\"anchor\" id=\"second_q\"></a>\n",
    "\n",
    "To evaluate the price behavior over the years we will create four plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "\n",
    "sns.lineplot(df, x = 'YrSold', y='SalePrice')\n",
    "\n",
    "plt.xticks(df['YrSold'].unique(), fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.ylabel('Average Price ($)', fontsize=14)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.title('Price behavior over the years', fontsize=18)\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "\n",
    "# how did price behave over the years\n",
    "\n",
    "df_dt = df.copy()\n",
    "\n",
    "year_price = df_dt.groupby('YrSold')['SalePrice'].mean().to_frame('AvgPrice')\n",
    "year_price['YearOnYearChange'] = year_price['AvgPrice'].pct_change()\n",
    "year_price['ChangeLabel'] = year_price['YearOnYearChange'].map(lambda x: \n",
    "                                                               f'+{x :.0%}' if x > 0 else f'{x :.0%}')\n",
    "\n",
    "# Create the plot\n",
    "sns.barplot(data=year_price, x=year_price.index, y='AvgPrice', color='steelblue', alpha=0.7)\n",
    "plt.axhline(y=year_price['AvgPrice'].mean(), linestyle='--', color='grey', label='Mean Average Price')\n",
    "\n",
    "for i, label in enumerate(year_price['ChangeLabel'][1:], start=1):\n",
    "    plt.text(i, year_price['AvgPrice'].iloc[i], label, ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "plt.title('Average Price (Year-on-Year % Change)', fontsize=18)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.ylabel('Average Price ($)', fontsize=14)\n",
    "plt.ylim(0, 200000)\n",
    "plt.gca().yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "plt.legend(loc='lower left')\n",
    "plt.yticks(fontsize=11)\n",
    "plt.xticks(fontsize=11)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "\n",
    "# combining month and year\n",
    "df_dt['SaleDate'] = df_dt.apply(lambda x: datetime.date(x['YrSold'], x['MoSold'], 1), axis=1)\n",
    "\n",
    "# how did the price behave over the months\n",
    "month_price = df_dt.groupby('SaleDate')['SalePrice'].mean().to_frame('AvgPrice')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "sns.lineplot(data=month_price, x=month_price.index, y='AvgPrice', color='steelblue')\n",
    "plt.axhline(y=month_price['AvgPrice'].mean(), linestyle='--', color='grey', label='Mean Average Price')\n",
    "\n",
    "plt.title('Average Price', fontsize=18)\n",
    "plt.xlabel('Sale Date', fontsize=14)\n",
    "plt.ylabel('Average Price ($)', fontsize=14)\n",
    "plt.gca().yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "plt.xticks(fontsize=11, rotation=45)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "\n",
    "month_sale = df_dt.groupby('SaleDate').size().to_frame('Sales')\n",
    "\n",
    "sns.lineplot(data=month_sale, x=month_sale.index, y='Sales', color='steelblue')\n",
    "plt.title('Monthly Sales', fontsize=18)\n",
    "plt.xlabel('Sale Date', fontsize=14)\n",
    "plt.ylabel('Number of sales', fontsize=14)\n",
    "plt.xticks(fontsize=11, rotation=45)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data covers the span of 5 years (2006-2010). Over that time average prices were pretty stable, centered around $180K, with with year-on-year variations under 5%.\n",
    "\n",
    "Sale Price fluctuates heavily from month to month. We can also notice some seasonality: at the beginning of each year (approx. until May) average prices decline, they reach their peak height in Septemberâ€“November, but usually drop again by December. \n",
    "\n",
    "But it's more interesting to check the seasonality by the number of sales, where the trend is the opposite: autumn has a significant drop in housing sales, so each observation gains more weight (and thus raises the average price). Peak sales are always in June-July (possibly before the beginning of the school year)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Features distribution <a class=\"anchor\" id=\"third_q\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical features to numerical\n",
    "\n",
    "df_cat = df.copy()\n",
    "# get dtypes in columns\n",
    "c_dtype = df.dtypes\n",
    "# we need to convert our categorical feature to numerical\n",
    "for c in c_dtype[c_dtype=='object'].index:\n",
    "    df_cat[c] = df_cat[c].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features distribution\n",
    "plt.figure()\n",
    "\n",
    "df_cat.hist(figsize=(20, 25), bins=50, xlabelsize=8, ylabelsize=8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that many numerical data are skewed, hence they will require normalization if we apply ML algorithms that assume normality.\n",
    "\n",
    "Let's look more closely at the label distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall distribution\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.distplot(df['SalePrice'], bins=15, color='steelblue', kde=False)\n",
    "plt.axvline(x=df['SalePrice'].mean(), linestyle='--', color='dimgrey', label='Avg price')\n",
    "plt.text(df['SalePrice'].mean(), 600, 'Avg price', rotation=90, va='bottom', ha='right', color='dimgrey')\n",
    "plt.title('Target Distribution', fontsize=18)\n",
    "plt.xlabel('Sale Price ($)', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.ylim(0, 600)\n",
    "plt.gca().xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df['SalePrice'].describe())\n",
    "print(f'95th percentile: {np.percentile(df[\"SalePrice\"], 95) :,.0f}')\n",
    "print(f'Skewness: {df[\"SalePrice\"].skew() :,.2f}')\n",
    "print(f'Kurtosis: {df[\"SalePrice\"].kurtosis() :,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While overall our target (Sale Price) is distributed normally, its distribution is heavily skewed to the right with very high prices as outliers. We can see it from the high skewness coefficient (>1), high positive kurtosis indicating heavy tails, as well as the histogram itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Features correlation with the label <a class=\"anchor\" id=\"fourth_q\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation index with the label using spearman methon, \n",
    "# since we can assume that it's possible to have nonlinear correlation among the features\n",
    "corr_feats = df_cat.corr(method='spearman')['SalePrice'].sort_values(ascending=False)\n",
    "h_corr_feats = corr_feats[abs(corr_feats) >= 0.5]\n",
    "h_corr_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest correlation index with the label have OverallQual and GrLivArea. Let's look at them:\n",
    "\n",
    "OverallQual: Rates the overall material and finish of the house\n",
    "\n",
    "       10\tVery Excellent\n",
    "       9\tExcellent\n",
    "       8\tVery Good\n",
    "       7\tGood\n",
    "       6\tAbove Average\n",
    "       5\tAverage\n",
    "       4\tBelow Average\n",
    "       3\tFair\n",
    "       2\tPoor\n",
    "       1\tVery Poor\n",
    "\n",
    "GrLivArea: Above grade (ground) living area square feet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 More EDA <a class=\"anchor\" id=\"fifth_q\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values\n",
    "\n",
    "Let's explore more columns with missing values and try to understand how we should deal with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "sns.set_style(\"whitegrid\")\n",
    "missing_val = df.isnull().sum()\n",
    "missing_val = missing_val[missing_val > 0]\n",
    "print(\"Total number of features with missing values in the training data set:\", len(missing_val))\n",
    "missing_val.sort_values(ascending=False, inplace=True)\n",
    "ax = missing_val.plot.bar()\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))\n",
    "plt.title(\"Features with missing values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain information from the data description file:\n",
    "\n",
    "Fence: Fence quality\n",
    "\t\t\n",
    "       GdPrv\tGood Privacy\n",
    "       MnPrv\tMinimum Privacy\n",
    "       GdWo\tGood Wood\n",
    "       MnWw\tMinimum Wood/Wire\n",
    "       NA\tNo Fence\n",
    "\n",
    "MasVnrType: Masonry veneer type\n",
    "\n",
    "       BrkCmn\tBrick Common\n",
    "       BrkFace\tBrick Face\n",
    "       CBlock\tCinder Block\n",
    "       None\tNone\n",
    "       Stone\tStone\n",
    "\n",
    "\n",
    "FireplaceQu: Fireplace quality\n",
    "\n",
    "       Ex\tExcellent - Exceptional Masonry Fireplace\n",
    "       Gd\tGood - Masonry Fireplace in main level\n",
    "       TA\tAverage - Prefabricated Fireplace in main living area or Masonry Fireplace in basement\n",
    "       Fa\tFair - Prefabricated Fireplace in basement\n",
    "       Po\tPoor - Ben Franklin Stove\n",
    "       NA\tNo Fireplace\n",
    "\n",
    "LotFrontage: Linear feet of street connected to property\n",
    "\n",
    "GarageType: Garage location\n",
    "\t\t\n",
    "       2Types\tMore than one type of garage\n",
    "       Attchd\tAttached to home\n",
    "       Basment\tBasement Garage\n",
    "       BuiltIn\tBuilt-In (Garage part of house - typically has room above garage)\n",
    "       CarPort\tCar Port\n",
    "       Detchd\tDetached from home\n",
    "       NA\tNo Garage\n",
    "\t\t\n",
    "GarageYrBlt: Year garage was built\n",
    "\n",
    "GarageFinish: Interior finish of the garage\n",
    "\n",
    "       Fin\tFinished\n",
    "       RFn\tRough Finished\t\n",
    "       Unf\tUnfinished\n",
    "       NA\tNo Garage\n",
    "\n",
    "GarageQual: Garage quality\n",
    "\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tTypical/Average\n",
    "       Fa\tFair\n",
    "       Po\tPoor\n",
    "       NA\tNo Garage\n",
    "\t\t\n",
    "GarageCond: Garage condition\n",
    "\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tTypical/Average\n",
    "       Fa\tFair\n",
    "       Po\tPoor\n",
    "       NA\tNo Garage\n",
    "\n",
    "BsmtQual: Evaluates the height of the basement\n",
    "\n",
    "       Ex\tExcellent (100+ inches)\t\n",
    "       Gd\tGood (90-99 inches)\n",
    "       TA\tTypical (80-89 inches)\n",
    "       Fa\tFair (70-79 inches)\n",
    "       Po\tPoor (<70 inches)\n",
    "       NA\tNo Basement\n",
    "\t\t\n",
    "BsmtCond: Evaluates the general condition of the basement\n",
    "\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tTypical - slight dampness allowed\n",
    "       Fa\tFair - dampness or some cracking or settling\n",
    "       Po\tPoor - Severe cracking, settling, or wetness\n",
    "       NA\tNo Basement\n",
    "\t\n",
    "BsmtExposure: Refers to walkout or garden level walls\n",
    "\n",
    "       Gd\tGood Exposure\n",
    "       Av\tAverage Exposure (split levels or foyers typically score average or above)\t\n",
    "       Mn\tMimimum Exposure\n",
    "       No\tNo Exposure\n",
    "       NA\tNo Basement\n",
    "\t\n",
    "BsmtFinType1: Rating of basement finished area\n",
    "\n",
    "       GLQ\tGood Living Quarters\n",
    "       ALQ\tAverage Living Quarters\n",
    "       BLQ\tBelow Average Living Quarters\t\n",
    "       Rec\tAverage Rec Room\n",
    "       LwQ\tLow Quality\n",
    "       Unf\tUnfinshed\n",
    "       NA\tNo Basement\n",
    "\n",
    "BsmtFinType2: Rating of basement finished area (if multiple types)\n",
    "\n",
    "       GLQ\tGood Living Quarters\n",
    "       ALQ\tAverage Living Quarters\n",
    "       BLQ\tBelow Average Living Quarters\t\n",
    "       Rec\tAverage Rec Room\n",
    "       LwQ\tLow Quality\n",
    "       Unf\tUnfinshed\n",
    "       NA\tNo Basement\n",
    "\n",
    "MasVnrArea: Masonry veneer area in square feet\n",
    "\n",
    "Electrical: Electrical system\n",
    "\n",
    "       SBrkr\tStandard Circuit Breakers & Romex\n",
    "       FuseA\tFuse Box over 60 AMP and all Romex wiring (Average)\t\n",
    "       FuseF\t60 AMP Fuse Box and mostly Romex wiring (Fair)\n",
    "       FuseP\t60 AMP Fuse Box and mostly knob & tube wiring (poor)\n",
    "       Mix\tMixed\n",
    "\n",
    "Similar as we discovered in 1.1 None value has a meaning to the next features: 'Fence', 'MasVnrType', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtFinType2', 'BsmtExposure', 'BsmtFinType1', 'BsmtCond', 'BsmtQual'. And it makes sense that the feature 'GarageYrBlt' has the same amount of missing values as other features about a Garage since there isn't a garage in these houses.\n",
    "\n",
    "It's necessary to understand how to deal with missing values in the next features: LotFrontage, MasVnrArea, and Electrical.\n",
    "\n",
    "At that point,  we will create a list of features where None value has a meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_wn = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'MasVnrType', 'FireplaceQu',\n",
    "       'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtFinType2', 'BsmtExposure',\n",
    "       'BsmtFinType1', 'BsmtCond', 'BsmtQual']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features correlation\n",
    "\n",
    "It would be useful to investigate more about the features correllation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate correlation matrix\n",
    "corr = df_cat.corr(method='spearman')\n",
    "\n",
    "# leave only features that have correration index with others > 0.5\n",
    "mask = (abs(corr) > 0.5)\n",
    "corr_s = corr[mask].sum()\n",
    "\n",
    "# remove others features from the heatmap\n",
    "corr.drop(corr_s[corr_s==1].index, inplace=True)\n",
    "corr.drop(corr_s[corr_s==1].index, axis=1, inplace=True)\n",
    "\n",
    "# Plotting the heatmap using Matplotlib and Seaborn\n",
    "plt.figure(figsize=(20, 16))\n",
    "#sns.heatmap(corr_matrix[mask], vmin=-0.8, vmax=0.8, square=True, annot=True, cmap='viridis')\n",
    "sns.heatmap(corr[mask], vmin=-1, vmax=1, square=True, annot=True, cmap='viridis')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Correlation Heatmap (>|0.5|)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above revealed, that some features have robust correlations, for instance, 'Fireplaces' and 'FireplaceQy', 'MiscFeature' and 'MiscVal'. We need to keep it in mind because it suggests potential multicollinearity, which can be problematic for certain types of regression models since it can affect the stability of the coefficient estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To establish a baseline we will build a simple Linear Regression model. \n",
    "\n",
    "To do so we will select features with the highest absolute value of the correlation coefficient, handle missing values among them, scale values and, eliminate features with high correlation coefficient between each other to avoid multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values\n",
    "df[h_corr_feats.index].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is strong correlation (>0.7) among the features\n",
    "feat_list = list(h_corr_feats.index)[1:]\n",
    "tmp_fl = []\n",
    "for f in feat_list:\n",
    "    corr_info = df_cat[feat_list].corr()[f].sort_values(ascending=False)\n",
    "    if corr_info[(abs(corr_info) >= 0.7) & (abs(corr_info) != 1)].any():\n",
    "        tmp_c = corr_info[(abs(corr_info) >= 0.7) & (abs(corr_info) != 1)]\n",
    "        tmp_fl.append(tmp_c.name)\n",
    "        \n",
    "        # to avoid printing duplicates\n",
    "        for i in tmp_c.index:\n",
    "            if i not in tmp_fl:\n",
    "                tmp_fl.append(i)\n",
    "                print(tmp_c, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8 features having strong correlation among each other. We should make a decision about each feature in pairs.\n",
    "\n",
    "1. TotalBsmtSF: Total square feet of basement area<br>\n",
    "GrLivArea: Above grade (ground) living area square feet\n",
    "\n",
    "The correlation between these features makes sense; however, GrLivArea has a stronger correlation with the label 'SalePrice'. Therefore, for the Linear Regression model, we will eliminate 'TotalBsmtSF'.\n",
    "\n",
    "2. GarageCars: Size of garage in car capacity<br>\n",
    "GarageArea: Size of garage in square feet\n",
    "\n",
    "The correlation between these features makes sense. Since 'GarageCars' has a stronger correlation with the label 'SalePrice', we will eliminate 'GarageArea', which also has missing values.\n",
    "\n",
    "3. GarageYrBlt: Year garage was built<br>\n",
    "YearBuilt: Original construction date\n",
    "\n",
    "For the same reasons, we will eliminate 'GarageYrBlt'.\n",
    "\n",
    "4. 1stFlrSF: First Floor square feet  <br>\n",
    "TotalBsmtSF: Total square feet of basement area\n",
    "\n",
    "For the same reasons, we will eliminate '1stFlrSF'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create final list of features\n",
    "list_feat_lr = ['OverallQual', 'GrLivArea', 'GarageCars', 'YearBuilt',\n",
    "       'FullBath', 'YearRemodAdd', 'TotRmsAbvGrd', 'Fireplaces', 'KitchenQual',\n",
    "       'ExterQual']\n",
    "\n",
    "# Scale values\n",
    "scaler = StandardScaler()\n",
    "df_cat[list_feat_lr] = scaler.fit_transform(df_cat[list_feat_lr])\n",
    "\n",
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_cat[list_feat_lr], df['SalePrice'], test_size=0.25)\n",
    "\n",
    "# train model\n",
    "ols_model = linear_model.LinearRegression()\n",
    "ols_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_ols = ols_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance using MSE\n",
    "print(f'MSE for OLS: {mean_squared_error(y_test, y_pred_ols)}')\n",
    "print(f'RMSE for OLS: {np.sqrt(mean_squared_error(np.log(y_test), np.log(y_pred_ols)))}')\n",
    "print(f'R^2 score for OLS: {ols_model.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data[list_feat_lr]\n",
    "test_data_cat = test_data.copy()\n",
    "test_data_cat = test_data_cat[list_feat_lr].fillna(0)\n",
    "# get dtypes in columns\n",
    "c_dtype = test_data_cat.dtypes\n",
    "# we need to convert our categorical feature to numerical\n",
    "for c in c_dtype[c_dtype=='object'].index:\n",
    "    test_data_cat[c] = test_data_cat[c].astype('category').cat.codes\n",
    "\n",
    "test_data_cat[list_feat_lr] = scaler.fit_transform(test_data_cat[list_feat_lr])\n",
    "y_tpred_ols = ols_model.predict(test_data_cat[list_feat_lr])\n",
    "\n",
    "# create submission file\n",
    "subm = pd.DataFrame()\n",
    "subm['Id'] = test_data['Id']\n",
    "subm['SalePrice'] = y_tpred_ols\n",
    "subm.set_index('Id').to_csv('submission_bl.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "#### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with a string label for the features where None value has a meaning\n",
    "df_fna = df.copy()\n",
    "df_fna[feat_wn] = df_fna[feat_wn].fillna('NA')\n",
    "new_mv = df_fna.isna().sum()\n",
    "new_mv[new_mv>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mva = df_fna[df_fna.loc[:,'MasVnrType'].isna()]['MasVnrArea']\n",
    "mva[mva > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of values MasVnrArea are 0 if MasVnrType is missing, but some of them has non zero value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvt = df_fna[df_fna.loc[:,'MasVnrArea'] == 0]['MasVnrType']\n",
    "print(mvt.unique())\n",
    "mvt[~mvt.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile two rows have existing MasVnrType while MasVnrArea == 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace MasVnrArea with 0 where MasVnrArea==1\n",
    "index_mva = df_fna[df_fna.loc[:,'MasVnrArea'] == 1].index\n",
    "df_fna.loc[index_mva,'MasVnrArea'] = 0\n",
    "\n",
    "# Replace MasVnrType in rows where MasVnrArea==0 with 'NoMasVnr' \n",
    "index_mvt = df_fna[(df_fna.loc[:,'MasVnrArea'] == 0) & (~df_fna.loc[:,'MasVnrType'].isna())].index\n",
    "df_fna.loc[index_mvt,'MasVnrType'] = 'NoMasVnr'\n",
    "\n",
    "# Fill missing values in MasVnrType with 'NoMasVnr' \n",
    "df_fna.loc[:,'MasVnrType'].fillna('NoMasVnr', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LotFrontage has 259 missing values. Let's use an SVM Regressor algorithm to estimate and fill in these missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_LF = df[~df.LotFrontage.isnull()]\n",
    "test_LF = df[df.LotFrontage.isnull()]\n",
    "target = train_LF['LotFrontage']\n",
    "\n",
    "print(f\"Number of filled LotFrontage data: {len(train_LF)}\")\n",
    "print(f\"Number of missing LotFrontage data: {len(test_LF)}\")\n",
    "\n",
    "display(pd.DataFrame(df['LotFrontage'].describe()).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the LotFrontage values in the Train LotFrontage dataset using a boxplot and distribution plot. Here's what we can see:\n",
    "\n",
    "* Many properties have low LotFrontage values, shown as a peak on the left side of the distribution plot. The boxplot suggests some of these values might be unusual, as they're far from the main cluster.\n",
    "* There are also quite a few properties with high LotFrontage values, going beyond what's typical.\n",
    "\n",
    "In simple terms, there are outliers present at both of the LotFrontage range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 4))\n",
    "sns.boxplot(target, ax=ax[0])\n",
    "sns.histplot(target, ax=ax[1], kde=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miscellaneous feature not covered in other categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fna[(df_fna['MiscVal'] != 0)][['MiscFeature']].groupby('MiscFeature').value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy columns based on values in MiscFeature\n",
    "dummy_columns = pd.get_dummies(df_fna['MiscFeature'], prefix='mf')\n",
    "\n",
    "# Multiply each dummy column by corresponding MiscVal\n",
    "for col in dummy_columns.columns:\n",
    "    dummy_columns[col] = dummy_columns[col] * df['MiscVal']\n",
    "\n",
    "# Concatenate the dummy columns with the original DataFrame\n",
    "df_fna = pd.concat([df_fna, dummy_columns], axis=1)\n",
    "\n",
    "# Drop the original 'MiscFeature' column\n",
    "df_fna.drop(['MiscFeature','MiscVal'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py4dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
